{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  99.9 %0.0 %12.3 %                        ]  38.7 %=====================>                   ]  51.0 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====================>                   ]  51.3 %>              ]  63.5 %===============================>         ]  75.8 %]  88.0 %>    ]  89.6 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m MbedTLS ─ v0.6.4\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      " \u001b[90m [739be429]\u001b[39m\u001b[93m ↑ MbedTLS v0.6.3 ⇒ v0.6.4\u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m MbedTLS → `~/.julia/packages/MbedTLS/CwGUN/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Gym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Flux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1186\n",
      "WARNING: could not import NNlib.cudata into Tracker\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using Flux\n",
    "using Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GymEnv(\"BipedalWalker-v2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_n = env.observation_space.shape[1]; # continuous state space\n",
    "a_n = env.action_space.shape[1]; # continuous action space\n",
    "ha_n = [400,400];\n",
    "hc_n = [300, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function weightSync(target_net, source_net, tau=0.001):\n",
    "    for i in size(m.layers):\n",
    "        target_net.layers[i].W = (1-tau)*target_net.layers[i].W + tau*source_net.layers[i].W;\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Replay\n",
    "    capacity::Float32\n",
    "    memory::Float32\n",
    "    position::Float32\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Replay(1000.0f0, 10000.0f0, 0.0f0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Replay(1000,10000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Replay:\n",
    "    capacity::Float32\n",
    "    memory\n",
    "    position::Float32\n",
    "end\n",
    "\n",
    "function initialize(r::Replay, init_len, env):\n",
    "    i = 0;\n",
    "    r.action_dim = env.action_space.shape[1]\n",
    "    while i < init_len:\n",
    "        s = reset!(env)\n",
    "        d = False\n",
    "        while not d:\n",
    "            a = rand(env.action_space.shape[1]).*(2).-1;\n",
    "            ns, r, d, _ = step!(env, a);\n",
    "            r.memory.append!((s,a,r,ns,d));\n",
    "            s = ns;\n",
    "            i +=1;\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function push(r::Replay, transition):\n",
    "    if length(r.memory)<=r.position:\n",
    "        r.memory.append!(None)\n",
    "    end\n",
    "    r.memory[r.position]=transition;\n",
    "    r.position = mod((r.position+1),r.capacity)\n",
    "end\n",
    "\n",
    "function sample(r::Replay, N):\n",
    "    return sample(r.memory,N)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct OnrsteinUhlenbeckProcess\n",
    "    theta::Float32\n",
    "    mu::Float32\n",
    "    sigma::Float32\n",
    "    dt::Float32\n",
    "    action_size\n",
    "    x\n",
    "end\n",
    "\n",
    "function step(OUP::OnrsteinUhlenbeckProcess)\n",
    "    xx = OUP.theta*([OUP.mu]*OUP.action_size-\n",
    "        OUP.x[-OUP.action_size:])*OUP.dt + \n",
    "        OUP.sigma*randn(zeros(OUP.action_size))\n",
    "    OUP.x = append!(OUP.x,xx)\n",
    "    return OUP.x[-OUP.action_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(24, 24, tanh), Dense(24, 24, tanh), Dense(24, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor = Chain(\n",
    "    Dense(s_n, ha_n[1], relu),\n",
    "    BatchNorm(ha_n[1]),\n",
    "    Dense(ha_n[1], ha_n[2], relu),\n",
    "    BatchNorm(ha_n[2]),\n",
    "    Dense(ha_n[2], a_n),\n",
    "    tanh)\n",
    "\n",
    "critic = Chain(\n",
    "    Dense(s_n,hc_n[1],relu),\n",
    "    BatchNorm(hc_n[1]),\n",
    "    Dense(hc_n[1]+a_n, hc_n[2],relu),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.050383    0.360395   0.984606\n",
       "  0.0547567  -0.224643   0.585206\n",
       "  0.791885    0.373463  -0.857316"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(3,3).*(2).-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0912641486376598"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_count = 2000;\n",
    "min_epsilon = 0.01;\n",
    "decay_rate = 5/episode_count;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1 total Rewards: -85.97788289192233\n",
      "episode 2 total Rewards: -98.68037809058097\n",
      "episode 3 total Rewards: -92.41382523298962\n",
      "episode 4 total Rewards: -99.93802021494935\n",
      "episode 5 total Rewards: -79.69650269939272\n",
      "episode 6 total Rewards: -102.57114505678385\n",
      "episode 7 total Rewards: -110.65297324995726\n",
      "episode 8 total Rewards: -100.0879210012217\n",
      "episode 9 total Rewards: -98.46423048953291\n",
      "episode 10 total Rewards: -85.04734643681674\n"
     ]
    }
   ],
   "source": [
    "# General Algorithm for Q learning\n",
    "\n",
    "# For each step in each episode: \n",
    "#     Use policy defined by training network to pick actions\n",
    "#     Update experience replay\n",
    "# After each episode: \n",
    "# Sample from experience replay\n",
    "# Update training net; (update target net after x episodes)\n",
    "\n",
    "# using Gym\n",
    "reward = 0;\n",
    "episode_count = 2000;\n",
    "min_epsilon = 0.01;\n",
    "decay_rate = 5/episode_count;\n",
    "\n",
    "for i=1:episode_count\n",
    "    # set epsilon for exploring policy\n",
    "    epsilon = min_epsilon + (1.0 - min_epsilon)*exp(-decay_rate*i)\n",
    "    total = 0\n",
    "    ob = reset!(env)\n",
    "#     render(env)#comment out this line if you do not want to visualize the environment\n",
    "    while true\n",
    "        Q_values = m(ob)\n",
    "        # exploration\n",
    "        if epsilon > Random.rand()\n",
    "            action = Random.rand(env.action_space.shape[1])\n",
    "        else\n",
    "            # take max of Q_values\n",
    "#         action = sample(env.action_space)\n",
    "        end\n",
    "        ob, reward, done, information = step!(env, action)\n",
    "        total += reward\n",
    "#         render(env)#comment out this line if you do not want to visualize the environment\n",
    "        done && break\n",
    "    end\n",
    "    # Experience reply\n",
    "    # update training net \n",
    "    i%10 && \n",
    "    println(\"episode $i total Rewards: $total\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       "  0.5131067509384377 \n",
       "  0.8626462959402228 \n",
       " -0.3850172680270889 \n",
       "  0.40907506858505505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.5091860357094704 \n",
       " 0.46913460209260993\n",
       " 0.03589676414598042\n",
       " 0.27638164170088775"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.rand(env.action_space.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State consists of hull angle speed, angular velocity, horizontal speed, vertical speed,\n",
    "# position of joints and joints angular speed, legs contact with ground, and 10 lidar\n",
    "# rangefinder measurements to help to deal with the hardcore version. There's no coordinates\n",
    "# in the state vector. Lidar is less useful in normal version, but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoxS(Float32[-Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf  …  -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf], Float32[Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf  …  Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf], (24,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoxS(Float32[-1.0, -1.0, -1.0, -1.0], Float32[1.0, 1.0, 1.0, 1.0], (4,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "# I think this is force on 4 joints\n",
    "# limits: -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "type BoxS has no field sample",
     "output_type": "error",
     "traceback": [
      "type BoxS has no field sample",
      "",
      "Stacktrace:",
      " [1] getproperty(::Any, ::Symbol) at ./sysimg.jl:18",
      " [2] top-level scope at In[44]:1"
     ]
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
